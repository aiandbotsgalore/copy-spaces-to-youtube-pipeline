name: Ingest Space

on:
  repository_dispatch:
    types: [ingest-space]
  workflow_dispatch:
    inputs:
      url:
        description: 'Twitter Space URL to download'
        required: true
        type: string

permissions:
  contents: write
  actions: write

concurrency:
  group: ingest-${{ github.event.client_payload.url || inputs.url }}
  cancel-in-progress: false

jobs:
  ingest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install ffmpeg
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install yt-dlp
        run: pip install yt-dlp

      - name: Get URL
        id: url
        run: |
          URL="${{ github.event.client_payload.url || inputs.url }}"
          echo "url=$URL" >> $GITHUB_OUTPUT
          SPACE_ID=$(echo "$URL" | grep -oE '[a-zA-Z0-9]+$')
          echo "space_id=$SPACE_ID" >> $GITHUB_OUTPUT
          echo "Processing: $SPACE_ID"

      - name: Download Space
        id: download
        run: |
          mkdir -p work
          DATE=$(date +%Y%m%d)
          SPACE_ID="${{ steps.url.outputs.space_id }}"
          URL="${{ steps.url.outputs.url }}"

          echo "Downloading $URL..."

          yt-dlp \
            --retries 3 \
            --fragment-retries 3 \
            --no-playlist \
            --restrict-filenames \
            --extract-audio \
            --audio-format mp3 \
            --audio-quality 0 \
            --embed-metadata \
            --write-info-json \
            --output "work/${DATE}_${SPACE_ID}_%(title)s.%(ext)s" \
            "$URL"

          MP3_FILE=$(find work -name "*.mp3" | head -1)
          JSON_FILE=$(find work -name "*.info.json" | head -1)

          if [[ -z "$MP3_FILE" ]]; then
            echo "::error::No MP3 produced"
            exit 1
          fi

          # Extract metadata
          if [[ -f "$JSON_FILE" ]]; then
            TITLE=$(python3 -c "import json; print(json.load(open('$JSON_FILE')).get('title','Unknown'))" 2>/dev/null || echo "Unknown")
            UPLOADER=$(python3 -c "import json; print(json.load(open('$JSON_FILE')).get('uploader','Unknown'))" 2>/dev/null || echo "Unknown")
            UPLOADER_ID=$(python3 -c "import json; print(json.load(open('$JSON_FILE')).get('uploader_id',''))" 2>/dev/null || echo "")
          else
            TITLE="Space_$SPACE_ID"
            UPLOADER="Unknown"
            UPLOADER_ID=""
          fi

          # Clean title
          TITLE=$(echo "$TITLE" | tr '_' ' ')

          echo "mp3_file=$MP3_FILE" >> $GITHUB_OUTPUT
          echo "title=$TITLE" >> $GITHUB_OUTPUT
          echo "uploader=$UPLOADER" >> $GITHUB_OUTPUT
          echo "uploader_id=$UPLOADER_ID" >> $GITHUB_OUTPUT
          echo "release_tag=${DATE}_${SPACE_ID}" >> $GITHUB_OUTPUT

      - name: Get Duration
        id: duration
        run: |
          DURATION=$(ffprobe -v error -show_entries format=duration \
            -of default=noprint_wrappers=1:nokey=1 "${{ steps.download.outputs.mp3_file }}" \
            | awk '{printf "%02d:%02d:%02d", ($1/3600), ($1%3600/60), ($1%60)}')
          echo "duration=$DURATION" >> $GITHUB_OUTPUT

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: ${{ steps.download.outputs.release_tag }}
          name: "${{ steps.download.outputs.title }}"
          files: ${{ steps.download.outputs.mp3_file }}
          body: |
            **Title:** ${{ steps.download.outputs.title }}
            **Host:** ${{ steps.download.outputs.uploader }} (@${{ steps.download.outputs.uploader_id }})
            **Duration:** ${{ steps.duration.outputs.duration }}
            **Source:** ${{ steps.url.outputs.url }}

            ---
            METADATA::DURATION::${{ steps.duration.outputs.duration }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Trigger Next URL
        if: always()
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Count currently running ingest workflows (excluding this one finishing)
          RUNNING=$(gh run list --workflow=batch_ingest.yml --status=in_progress -L 100 --json databaseId | jq 'length')
          echo "Currently running: $RUNNING"

          # If under limit (10), check if there are more URLs to process
          if [[ "$RUNNING" -lt 10 ]]; then
            # Get the queue file content
            QUEUE_CONTENT=$(gh api repos/${{ github.repository }}/contents/batch_queue.txt \
              --jq '.content' 2>/dev/null | base64 -d 2>/dev/null || echo "")

            if [[ -n "$QUEUE_CONTENT" ]]; then
              # Get count of URLs in queue
              QUEUE_COUNT=$(echo "$QUEUE_CONTENT" | grep -c -v '^[[:space:]]*$' || echo "0")
              echo "URLs in queue: $QUEUE_COUNT"

              # Calculate how many more we can start
              SLOTS=$((10 - RUNNING))
              echo "Available slots: $SLOTS"

              # Trigger jobs for available slots
              echo "$QUEUE_CONTENT" | grep -v '^[[:space:]]*$' | head -n $SLOTS | while read NEXT_URL; do
                if [[ -n "$NEXT_URL" ]]; then
                  echo "Triggering: $NEXT_URL"
                  gh workflow run batch_ingest.yml -f url="$NEXT_URL" || true
                  sleep 1
                fi
              done
            else
              echo "Queue is empty or not accessible"
            fi
          else
            echo "Already at max concurrent jobs"
          fi
